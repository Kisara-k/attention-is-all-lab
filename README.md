# attention-is-all-lab
Reproducing the Transformer architecture from attention is all you need.
